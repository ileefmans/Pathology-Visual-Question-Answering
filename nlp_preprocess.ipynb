{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ianleefmans/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class text_process:\n",
    "    \"\"\"\n",
    "    Class for preprocessing text.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,text):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text : a pd column of 'documents' to be vectorized \n",
    "            \n",
    "            \"\"\"\n",
    "        self.text = text\n",
    "        \n",
    "    \n",
    "    def pd_col_to_list(self):\n",
    "        \"\"\"\n",
    "        \n",
    "            Converts pandas column to a LIST of comma-separated text ('documents') before it is to be vectorized.\n",
    "            For example, index 0 of the list = the first question (or answer), and so on.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        doc_list = []\n",
    "        for i in self.text:\n",
    "            doc_list.append(i)\n",
    "            \n",
    "        return doc_list\n",
    "        \n",
    "        \n",
    "    def remove_stopwords(self, doc_list):    \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            doc_list: output from pd_col_to_list, a list of comma separated text ('documents')\n",
    "        \n",
    "            Removes stop_words, according to the stop words nltk corpus, before the list is to be vectorized.\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        stop_words = stopwords.words('english')\n",
    "        for j in range(len(doc_list)):\n",
    "            doc_list[j] = text_to_word_sequence(doc_list[j])\n",
    "            for i in stop_words:\n",
    "                count=0\n",
    "                while count==0:\n",
    "                    try:\n",
    "                        doc_list[j].remove(i)\n",
    "                    except:\n",
    "                        count+=1\n",
    "                    finally:\n",
    "                        pass\n",
    "        \n",
    "        return doc_list\n",
    "        \n",
    "\n",
    "    def text_to_vec(self, doc_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            doc_list: output from remove_stopwords(), a list of comma separated text ('documents') where stop words\n",
    "                       have been removed\n",
    "        \n",
    "        \n",
    "            Converts list of comma-separated 'documents' to a vector, using tf-idf. This is done after stop words \n",
    "            have been removed (with remove_stopwords()). Utilizes the keras tokenizer, which separates on spaces, \n",
    "            makes all tokens lowercase and removes punctuation. Function then stems the tokens, using the \n",
    "            PorterStemmer from nltk. Finally, it returns the preprocessed tokens in vector form.\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        ## Keras tokenizer\n",
    "        \n",
    "        tok = Tokenizer()\n",
    "        tok.fit_on_texts(doc_list)\n",
    "        \n",
    "        tokens = list(tok.word_counts)\n",
    "        \n",
    "        ## Stem words \n",
    "        \n",
    "        ps = PorterStemmer()\n",
    "        for i in range(len(tokens)): #i = question index (i.e. question1, question2, etc...)\n",
    "            tokens[i] = (ps.stem(tokens[i]))\n",
    "        \n",
    "        ## Return tf-idf matrix\n",
    "        \n",
    "        matrx = tok.texts_to_matrix(tokens, mode='tfidf')\n",
    "        \n",
    "        return matrx, tok.get_config()\n",
    "    \n",
    "    \n",
    "    def text_preprocess(self):\n",
    "\n",
    "        list_form = text_process.pd_col_to_list(self)\n",
    "        no_stops = text_process.remove_stopwords(self,list_form)\n",
    "        final_vec = text_process.text_to_vec(self,no_stops)\n",
    "        \n",
    "        return final_vec\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Making example questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['What year was pathology founded?', 'What does pathology mean?', 'Name five viral diseases',\n",
    "             'Where is the liver located?', 'What does the liver do?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd_col_to_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function may be irrelavant - can likely edit to use on pd column or delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleantxt = text_process(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What year was pathology founded?',\n",
       " 'What does pathology mean?',\n",
       " 'Name five viral diseases',\n",
       " 'Where is the liver located?',\n",
       " 'What does the liver do?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques_list = cleantxt.pd_col_to_list()\n",
    "ques_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice all stopwords have been removed and it is now a nested list of comma-separated words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['year', 'pathology', 'founded'],\n",
       " ['pathology', 'mean'],\n",
       " ['name', 'five', 'viral', 'diseases'],\n",
       " ['liver', 'located'],\n",
       " ['liver']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_stops = cleantxt.remove_stopwords(ques_list)\n",
    "no_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text_to_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts the above to a matrix, using the term-frequency inverse-document frequency (tfidf) approach. This function also stems the words before returning the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.        , 0.        , 1.25276297, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         1.25276297, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 1.25276297, 0.        , 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 1.25276297, 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 1.25276297, 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.98082925, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " {'num_words': None,\n",
       "  'filters': '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
       "  'lower': True,\n",
       "  'split': ' ',\n",
       "  'char_level': False,\n",
       "  'oov_token': None,\n",
       "  'document_count': 5,\n",
       "  'word_counts': '{\"year\": 1, \"pathology\": 2, \"founded\": 1, \"mean\": 1, \"name\": 1, \"five\": 1, \"viral\": 1, \"diseases\": 1, \"liver\": 2, \"located\": 1}',\n",
       "  'word_docs': '{\"year\": 1, \"pathology\": 2, \"founded\": 1, \"mean\": 1, \"viral\": 1, \"diseases\": 1, \"name\": 1, \"five\": 1, \"located\": 1, \"liver\": 2}',\n",
       "  'index_docs': '{\"3\": 1, \"1\": 2, \"4\": 1, \"5\": 1, \"8\": 1, \"9\": 1, \"6\": 1, \"7\": 1, \"10\": 1, \"2\": 2}',\n",
       "  'index_word': '{\"1\": \"pathology\", \"2\": \"liver\", \"3\": \"year\", \"4\": \"founded\", \"5\": \"mean\", \"6\": \"name\", \"7\": \"five\", \"8\": \"viral\", \"9\": \"diseases\", \"10\": \"located\"}',\n",
       "  'word_index': '{\"pathology\": 1, \"liver\": 2, \"year\": 3, \"founded\": 4, \"mean\": 5, \"name\": 6, \"five\": 7, \"viral\": 8, \"diseases\": 9, \"located\": 10}'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = cleantxt.text_to_vec(no_stops)\n",
    "vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 1.25276297, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.25276297, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.25276297, 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.25276297, 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.25276297, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.98082925, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary of all counts/values of matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_words': None,\n",
       " 'filters': '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
       " 'lower': True,\n",
       " 'split': ' ',\n",
       " 'char_level': False,\n",
       " 'oov_token': None,\n",
       " 'document_count': 5,\n",
       " 'word_counts': '{\"year\": 1, \"pathology\": 2, \"founded\": 1, \"mean\": 1, \"name\": 1, \"five\": 1, \"viral\": 1, \"diseases\": 1, \"liver\": 2, \"located\": 1}',\n",
       " 'word_docs': '{\"founded\": 1, \"pathology\": 2, \"year\": 1, \"mean\": 1, \"five\": 1, \"viral\": 1, \"diseases\": 1, \"name\": 1, \"located\": 1, \"liver\": 2}',\n",
       " 'index_docs': '{\"4\": 1, \"1\": 2, \"3\": 1, \"5\": 1, \"7\": 1, \"8\": 1, \"9\": 1, \"6\": 1, \"10\": 1, \"2\": 2}',\n",
       " 'index_word': '{\"1\": \"pathology\", \"2\": \"liver\", \"3\": \"year\", \"4\": \"founded\", \"5\": \"mean\", \"6\": \"name\", \"7\": \"five\", \"8\": \"viral\", \"9\": \"diseases\", \"10\": \"located\"}',\n",
       " 'word_index': '{\"pathology\": 1, \"liver\": 2, \"year\": 3, \"founded\": 4, \"mean\": 5, \"name\": 6, \"five\": 7, \"viral\": 8, \"diseases\": 9, \"located\": 10}'}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatively, you can just use text_preprocess in one step:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same result as above, it just returns the final matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.        , 0.        , 1.25276297, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         1.25276297, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 1.25276297, 0.        , 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 1.25276297, 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 1.25276297, 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.98082925, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " {'num_words': None,\n",
       "  'filters': '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
       "  'lower': True,\n",
       "  'split': ' ',\n",
       "  'char_level': False,\n",
       "  'oov_token': None,\n",
       "  'document_count': 5,\n",
       "  'word_counts': '{\"year\": 1, \"pathology\": 2, \"founded\": 1, \"mean\": 1, \"name\": 1, \"five\": 1, \"viral\": 1, \"diseases\": 1, \"liver\": 2, \"located\": 1}',\n",
       "  'word_docs': '{\"year\": 1, \"pathology\": 2, \"founded\": 1, \"mean\": 1, \"viral\": 1, \"diseases\": 1, \"name\": 1, \"five\": 1, \"located\": 1, \"liver\": 2}',\n",
       "  'index_docs': '{\"3\": 1, \"1\": 2, \"4\": 1, \"5\": 1, \"8\": 1, \"9\": 1, \"6\": 1, \"7\": 1, \"10\": 1, \"2\": 2}',\n",
       "  'index_word': '{\"1\": \"pathology\", \"2\": \"liver\", \"3\": \"year\", \"4\": \"founded\", \"5\": \"mean\", \"6\": \"name\", \"7\": \"five\", \"8\": \"viral\", \"9\": \"diseases\", \"10\": \"located\"}',\n",
       "  'word_index': '{\"pathology\": 1, \"liver\": 2, \"year\": 3, \"founded\": 4, \"mean\": 5, \"name\": 6, \"five\": 7, \"viral\": 8, \"diseases\": 9, \"located\": 10}'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleantxt.text_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
